import { CameraView, CameraType, useCameraPermissions } from 'expo-camera';
import { useState, useRef, useEffect} from 'react';
import { Button, ScrollView, StyleSheet, Text, TouchableOpacity, View, Image } from 'react-native';
import { useRouter, useLocalSearchParams } from 'expo-router';
import axios from 'axios';

export default function App() {
  const [facing, setFacing] = useState<CameraType>('front');
  const [faces, setFaces] = useState([]); // Store detected faces
  const [permission, requestPermission] = useCameraPermissions();
  const [verificationResults, setVerificationResults] = useState(null); // Store API response
  const [detectedImage, setDetectedImage] = useState(null); // Store detected faces image path
  const serverIP = '192.168.0.105';


  const cameraRef = useRef(null);
  const params = useLocalSearchParams();
  const { id } = params; // Extract the `id` parameter
  
  const [isCapturing, setIsCapturing] = useState(false); // Flag to start/stop capturing frames
  useEffect(() => {
    // Setup interval to send frames every second
    let interval;
    if (isCapturing) {
      interval = setInterval(() => {
        captureImage();
      }, 1500); // Send a frame every second
    }

    return () => clearInterval(interval); // Cleanup the interval when component unmounts or when isReady changes
  }, [isCapturing]);

  if (!permission) {
    // Camera permissions are still loading.
    return <View />;
  }

  if (!permission.granted) {
    // Camera permissions are not granted yet.
    return (
      <View style={styles.container}>
        <Text style={styles.message}>We need your permission to show the camera</Text>
        <Button onPress={requestPermission} title="Grant Permission" />
      </View>
    );
  }


  //capture image
  const captureImage = async () => {
    if (cameraRef.current) {
      const photo = await cameraRef.current.takePictureAsync();
      const { uri, width, height } = photo;
  
      const formData = new FormData();
      formData.append('image', {
        uri,
        name: 'photo.jpg',
        type: 'image/jpeg',
      });
      formData.append('width', width.toString());
      formData.append('height', height.toString());
      formData.append('user_id', id);  // Send user_id as part of the request
  
      try {
        const response = await axios.post(`http://${serverIP}:8000/verify_face/`, formData, {
          headers: {
            'Content-Type': 'multipart/form-data',
          },
        });
  
        // console.log('Number of faces detected:', response.data.faces.length); // Log number of faces
        const { verification_results, detected_image_path } = response.data;
        const newDetectedImage = `http://${serverIP}:8000/${detected_image_path}?t=${new Date().getTime()}`;

        // Update state with verification results and detected image
        setVerificationResults(verification_results);
        setDetectedImage(newDetectedImage);
        console.log(newDetectedImage);

        // Check if any verification result is TRUE
        if (verification_results.some(result => result.verified)) {
          setIsCapturing(false); // Stop capturing frames
        }
        } catch (error) {
          alert('No face detected!');
}
    }
  };

  return (
    <View style={styles.container}>
      {!verificationResults ? (
        <>
          <CameraView style={styles.camera} facing={facing} ref={cameraRef} animateShutter={false}
                  onCameraReady={() => setIsCapturing(true)} // Set the camera to ready when initialized
>
            {/* <View style={styles.buttonContainer}>
              <TouchableOpacity style={styles.button} onPress={captureImage}>
                <Text style={styles.text}>Capture</Text>
              </TouchableOpacity>
            </View> */}
          </CameraView>
        </>
      ) : (
        <ScrollView contentContainerStyle={styles.resultsContainer}>
          {detectedImage && (
            <Image source={{ uri: detectedImage }} style={styles.detectedImage} />
          )}
          <Text style={styles.resultHeader}>Verification Results</Text>
          {verificationResults.map((result, index) => (
            <View key={index} style={styles.resultItem}>
              <Text>Face {index + 1}:</Text>
              <Text>Verified: {result.verified ? 'Yes' : 'No'}</Text>
              <Text>Similarity: {(result.similarity * 100).toFixed(2)}%</Text>
              <Text>Distance: {result.distance.toFixed(4)}</Text>
            </View>
          ))}
          <Button
            title="Capture Again"
            onPress={() => {
              setVerificationResults(null); // Reset results to retake photo
            }}
          />
        </ScrollView>
      )}
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    justifyContent: 'center',
  },
  message: {
    textAlign: 'center',
    paddingBottom: 10,
  },
  camera: {
    flex: 1,
    width: 350, // Set a fixed width
    borderRadius: 150, // Make it circular (width/2)
    overflow: 'hidden', // Ensure content stays within the circle
    alignSelf: 'center', // Center the camera on the screen
  },
  buttonContainer: {
    flex: 1,
    flexDirection: 'row',
    backgroundColor: 'transparent',
    margin: 64,
  },
  button: {
    flex: 1,
    alignSelf: 'flex-end',
    alignItems: 'center',
  },
  text: {
    fontSize: 24,
    fontWeight: 'bold',
    color: 'white',
  },
  resultsContainer: {
    alignItems: 'center',
    padding: 16,
  },
  detectedImage: {
    width: '100%',
    height: 300,
    resizeMode: 'contain',
    marginBottom: 16,
  },
  resultHeader: {
    fontSize: 24,
    fontWeight: 'bold',
    marginBottom: 16,
  },
  resultItem: {
    marginBottom: 16,
    padding: 8,
    borderWidth: 1,
    borderColor: '#ccc',
    borderRadius: 8,
    width: '90%',
  },
});






















#backend:

# detector = MTCNN()
# @api_view(['POST'])
# def verify_face(request):
#     if 'image' not in request.FILES:
#         print(f"[DEBUG] No Image Provided")
#         return Response({'error': 'No image provided'}, status=400)

#     try:
#         # 1. Process the Captured Image
#         image_file = request.FILES['image']
#         img = Image.open(image_file).convert('RGB')

#         # Resize image for detection
#         original_width, original_height = img.size
#         img_resized = img.resize((240, 240))
#         img_array = np.array(img_resized)

#         # Detect faces using MTCNN
#         detections = detector.detect_faces(img_array)

#         if len(detections) == 0:
#             face = 0
#             return Response({face})

#         # Prepare to draw bounding boxes and crop faces
#         draw = ImageDraw.Draw(img_resized)
#         cropped_faces = []

#         for detection in detections:
#             # Bounding box in resized image
#             x_resized, y_resized, width_resized, height_resized = detection['box']

#             # Scale bounding box back to original image dimensions
#             x = int(x_resized * original_width / 240)
#             y = int(y_resized * original_height / 240)
#             width = int(width_resized * original_width / 240)
#             height = int(height_resized * original_height / 240)

#             # Draw bounding box on resized image
#             draw.rectangle(
#                 [(x_resized, y_resized), (x_resized + width_resized, y_resized + height_resized)], 
#                 outline="red", 
#                 width=3
#             )

#             # Crop face from the original image
#             cropped_face = img.crop((x, y, x + width, y + height))
#             cropped_faces.append(cropped_face)

#         # Save the detected face image with bounding boxes
#         detected_faces_path = os.path.join(settings.MEDIA_ROOT, "images", "detected_faces.jpg")
#         img_resized.save(detected_faces_path)

#         # Save the cropped faces temporarily
#         cropped_face_paths = []
#         for i, cropped_face in enumerate(cropped_faces):
#             cropped_face_path = os.path.join(settings.MEDIA_ROOT, "images", f"cropped_face_{i}.jpg")
#             cropped_face.save(cropped_face_path)
#             cropped_face_paths.append(cropped_face_path)

#         # 2. Retrieve the Reference Image from Database
#         user_id = request.POST.get('user_id')
#         print(f"[DEBUG] user ID: {user_id}")

#         if not user_id:
#             return Response({'error': 'user_id is required'}, status=status.HTTP_400_BAD_REQUEST)

#         user = Employee.objects.filter(id=user_id).first()
#         if not user:
#             return Response({'error': 'User not found'}, status=404)

#         if not user.faceImage:
#             return Response({'error': 'Face image not found for this user'}, status=404)
        
#         print(f"[DEBUG] user image: {user.faceImage}")

#         reference_image_path = os.path.join(settings.MEDIA_ROOT, str(user.faceImage))  # Adjust path if needed
#         print(f"[DEBUG] reference_image_path: {reference_image_path}")

#         # 3. Face Verification Using DeepFace
#         verification_results = []
#         for face_path in cropped_face_paths:
#             try:
# # result = DeepFace.verify(img1_path, img2_path, model_name="VGG-Face", detector_backend="opencv", distance_metric="cosine", enforce_detection=True, align=True, normalization="base")

#                 result = DeepFace.verify(
#                     img1_path=face_path, # Crop Image
#                     img2_path=reference_image_path, # User Face Image in Database
#                     model_name="Facenet",  # or "VGG-Face"
#                     enforce_detection=False
#                 )
#                  # Extract the distance or similarity score
#                 distance = result['distance']  # The smaller the distance, the more similar the faces
                
#                 # Set the threshold to 0.3  , distance need to < threshold
#                 threshold = 0.4
#                 detected_image_path = "/media/images/detected_faces.jpg"
#                 # Check if faces are verified based on the threshold
#                 if distance < threshold:
#                     verification_results.append({
#                     'face_path': face_path,
#                     'verified': True,
#                     'distance': result['distance'],
#                     'threshold': result['threshold'],
#                     'similarity': 1 - result['distance'],  # Calculate similarity
#                 })                    
#                 break
            
                    
#                 # print(f"[DEBUG] Result: {verification_results}")
#                 # print(f"[DEBUG] detected_image_path: {detected_image_path}")



#             except Exception as e:
#                 print(f"Error verifying face {face_path} against reference: {e}")
#                 verification_results.append({'face_path': face_path, 'error': str(e)})

#         if verification_results and any(result['verified'] for result in verification_results):
#             # If at least one face was verified, log attendance
#             # Get today's date and time
#             now = datetime.now()
#             today = now.date()

#             # Define valid check-in and check-out times
#             # check_in_start = time(21, 0) 
#             # check_in_end = time(21, 51)  
#             # check_out_start = time(21, 52)  
#             # check_out_end = time(23, 0)    
#             # Retrieve check-in and check-out times from the database
#             try:
#                 check_in_check_out_time = CheckInCheckOutTime.objects.first()
#                 check_in_start = check_in_check_out_time.check_in_start_time
#                 check_in_end = check_in_check_out_time.check_in_end_time
#                 check_out_start = check_in_check_out_time.check_out_start_time
#                 check_out_end = check_in_check_out_time.check_out_end_time
#             except CheckInCheckOutTime.DoesNotExist:
#                 return Response({'error': 'Check-in/check-out times not set'}, status=404)
            
#             attendance, created = AttendanceLog.objects.get_or_create(employee=user, date=today)
#             print(f'[debug] now time:', now.time() )

#             if not created:
#                 # Attendance already exists, check if it's check-out time
#                 if attendance.check_out_time is None:
#                     if check_out_start <= now.time() <= check_out_end:
#                         attendance.check_out_time = now
#                         attendance.save()
#                         message = "Check-out successful"
#                     else:
#                         message = f"Check-out is only allowed between {check_out_start} and {check_out_end}."
#                 else:
#                     message = "Attendance already logged for today"
#             else:
#                 # Attendance not recorded yet, allow check-in
#                 if check_in_start <= now.time() <= check_in_end:
#                     attendance.check_in_time = now
#                     attendance.save()
#                     message = "Check-in successful"
#                 else:
#                     attendance.delete()  # Remove the created record if check-in is not allowed
#                     message = f"Check-in is only allowed between {check_in_start} and {check_in_end}."

#             print(f"[DEBUG] Attendance: {message}")
#         else:
#             message = "Face verification failed"

#         # Return Response
#         return Response({
#             'message': 'Face(s) detected and verification performed successfully',
#             'faces_detected': len(detections),
#             'verification_results': verification_results,
#             'detected_image_path': detected_image_path,  # Relative path for accessing the image,
#             'similarity': verification_results
#         })

#     except Exception as e:
#         print("Error during face verification:", str(e))
#         return Response({'error': f'Error during face verification: {str(e)}'}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
